%% aut-tag-llm architecture diagram (Mermaid)
flowchart LR
    subgraph Env["Environment & Configuration"]
        ENV[.env.local / Environment variables<br/>HUGGINGFACE_API_KEY, *]
        CFG[config.py<br/>Centralizes settings]
        ENV --> CFG
    end

    subgraph Ingestion["Data Ingestion & ETL"]
        INPUT[[Excel spreadsheet in inputs/]]
        IO[io_utils<br/>ensure_directories + resolve_input_file]
        PREP[preprocessing_utils<br/>load_dataset + clean text + ensure NLTK]
        INPUT --> IO --> PREP
    end

    ORCH[aut.py<br/>Pipeline Orchestrator]
    CFG --> ORCH
    PREP --> ORCH

    DECIDE{MODEL_BACKEND?}
    ORCH --> DECIDE

    subgraph HFBackend["HF API backend (default)"]
        HF[hf_api_utils<br/>gradio_client]
        HFF[Hugging Face Space / Inference Endpoint]
        HF --> HFF
    end
    DECIDE -->|hf| HF

    subgraph LLMBackend["LLM backend"]
        LLM[llm_utils<br/>OpenAI-compatible calls]
        LLMAPI[Hugging Face Inference / Custom LLM API]
        LLM --> LLMAPI
    end
    DECIDE -->|llm| LLM

    subgraph BERTBackend["Local BERT fine-tuning"]
        BERTTRAIN[modeling_utils<br/>train_and_evaluate_bert]
        BERTINFER[apply_bert_model]
        BERTTRAIN --> BERTINFER
    end
    DECIDE -->|bert| BERTTRAIN

    subgraph ClassicBackend["Classic ML backend"]
        CLASSIC[modeling_utils<br/>TF-IDF/BoW + Logistic Regression]
    end
    DECIDE -->|ml| CLASSIC

    subgraph LocalBackend["Local transformers backend"]
        LOCAL[local_model_utils<br/>transformers.pipeline]
    end
    DECIDE -->|local| LOCAL

    HF & LLM & BERTINFER & CLASSIC & LOCAL --> CLASSIFIED[(Classified dataframe)]

    subgraph PostProcessing["Post-processing & Delivery"]
        REPORT[reporting_utils<br/>save_classified_data + metrics JSON]
        VIS[visualization_utils<br/>word clouds + charts]
        EMAIL[email_utils<br/>send_result_email]
    end
    CLASSIFIED --> REPORT
    CLASSIFIED --> VIS
    CLASSIFIED --> EMAIL

    REPORT --> EXCEL[[output/tagged_file.xlsx]]
    REPORT --> JSON[[inputs/nlp_metrics.json]]
    VIS --> WORDCLOUDS[[output/nlp_visualizations/*]]
    EMAIL --> STAKEHOLDERS[Stakeholder notification]

    subgraph QA["Quality Automation & Observability"]
        AUT_TESTS[robots/aut_tests.sh<br/>bootstrap venv + pytest + dashboard]
        PYTEST[tests/* + pytest.ini]
        DASHBOARD[dashboards/test_metrics_dashboard.py<br/>Streamlit metrics]
        AUT_TESTS --> PYTEST --> ORCH
        AUT_TESTS --> DASHBOARD
        DASHBOARD --> JSON
    end
